{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dcekit in /usr/local/lib/python3.6/dist-packages (2.4.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from dcekit) (1.5.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from dcekit) (1.1.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from dcekit) (0.24.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from dcekit) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->dcekit) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->dcekit) (2020.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas->dcekit) (1.11.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->dcekit) (1.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->dcekit) (2.1.0)\n",
      "Requirement already satisfied: xlrd==1.2.0 in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.6/dist-packages (3.0.6)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.6/dist-packages (from openpyxl) (1.0.1)\n",
      "Requirement already satisfied: jdcal in /usr/local/lib/python3.6/dist-packages (from openpyxl) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install dcekit\n",
    "!pip install xlrd==1.2.0\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dcekit.sampling import kennard_stone \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def loadData(config, zeroReplace=-1, removeLessThan=None, removeGreaterThan=None):\n",
    "    \"\"\"\n",
    "    Retrieves data from Excel file and optionally writes it out to serialized format\n",
    "    \"\"\"\n",
    "    configs = json.load(open(config))\n",
    "    xl_file = configs.get('xl_file')\n",
    "    target_column = configs.get('target_column')\n",
    "    descrptr_columns = configs.get('descrptr_columns')\n",
    "    err_column = configs.get('error_column')\n",
    "    name_col = configs.get('ligand_names')\n",
    "    absolute_yield = configs.get('absolute_yield')\n",
    "\n",
    "    df = pd.read_excel(xl_file)#, engine='openpyxl')\n",
    "    absYields = df[absolute_yield].to_numpy()\n",
    "    err_col = df[err_column].to_numpy()\n",
    "    # remove any data which does not have our yield cutoff\n",
    "    if removeLessThan is not None and removeGreaterThan is None:\n",
    "        # print(\"Input data set ({} total): \".format(len(df.index)),df[name_col])\n",
    "        remove_idxs = [i for i in range(0,len(absYields)) if absYields[i]<removeLessThan]\n",
    "        print(\"Removing the following ligands ({} total):\".format(len(remove_idxs)), ', '.join(df[name_col].to_numpy()[remove_idxs]))\n",
    "        df.drop(remove_idxs,inplace=True)\n",
    "        print(\"{} ligands remaining.\".format(len(df.index)))\n",
    "    elif removeGreaterThan is not None:\n",
    "        remove_idxs = [i for i in range(0,len(err_col)) if err_col[i]>removeGreaterThan]\n",
    "        print(\"Removing the following ligands ({} total):\".format(len(remove_idxs)), ', '.join(df[name_col].to_numpy()[remove_idxs]))\n",
    "        df.drop(remove_idxs,inplace=True)\n",
    "        print(\"{} ligands remaining.\".format(len(df.index)))\n",
    "\n",
    "    ligNames = df[name_col].to_numpy()\n",
    "    y = df[target_column].to_numpy()\n",
    "    # replace any zeros to avoid inversion errors\n",
    "    y[y==0] = zeroReplace\n",
    "    descriptor_names = descrptr_columns\n",
    "    X = df[descrptr_columns].to_numpy()\n",
    "    # pull and process weight column into shape of input array\n",
    "    weights = df[err_column].to_numpy()  # read it\n",
    "    weights[weights == 0] = np.min(weights[weights > 0])  # replace 0 standard error with lowest other error\n",
    "    weights = 1./weights  # invert\n",
    "    weights = weights[np.newaxis]  # change from 1D to 2D\n",
    "    weights = weights.T  # transpose to column vector\n",
    "    sample_weights = weights\n",
    "    feature_weights = np.repeat(weights, len(df[descrptr_columns].columns), axis=1)  # copy columns across to match input data\n",
    "    del weights\n",
    "\n",
    "    return X, y, feature_weights, sample_weights, ligNames\n",
    "\n",
    "def splitData(ttd, randState=None, splitter=None, trainSize=0.80):\n",
    "    # split response, features, and weights into train and test set\n",
    "    if randState is None:\n",
    "        randState = random.randint(1,1e9)\n",
    "        print('Random Seed: ',randState)\n",
    "    if splitter is None:\n",
    "        X_train, X_test, y_train, y_test, f_weights_train, f_weights_test, s_weights_train, s_weights_test, ln_train, ln = train_test_split(ttd.X, ttd.y, ttd.f_weights, ttd.s_weights, ttd.ln, train_size=trainSize, random_state=randState)\n",
    "    elif splitter == 'kennard_stone':\n",
    "        # get the appropriate number of training samples\n",
    "        temp, _ = train_test_split(ttd.y, train_size=trainSize)\n",
    "        train_idxs, test_idxs = kennard_stone(ttd.y.reshape(-1, 1),len(temp))\n",
    "    else:\n",
    "        raise(NotImplementedError)\n",
    "    if splitter is not None:\n",
    "        X_train = np.array([ttd.X[i] for i in train_idxs])\n",
    "        X_test = np.array([ttd.X[i] for i in test_idxs])\n",
    "        y_train = np.array([ttd.y[i] for i in train_idxs])\n",
    "        y_test = np.array([ttd.y[i] for i in test_idxs])\n",
    "        f_weights_train = np.array([ttd.f_weights[i] for i in train_idxs])\n",
    "        f_weights_test = np.array([ttd.f_weights[i] for i in test_idxs])\n",
    "        s_weights_train = np.array([ttd.s_weights[i] for i in train_idxs])\n",
    "        s_weights_test = [ttd.s_weights[i] for i in test_idxs]\n",
    "        ln_train = np.array([ttd.ln[i] for i in train_idxs])\n",
    "        ln = np.array([ttd.ln[i] for i in test_idxs])\n",
    "    return X_train, X_test, y_train, y_test, f_weights_train, f_weights_test, s_weights_train, s_weights_test, ln_train, ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the following ligands (20 total): 2-L12, 2-L11, 2-L7, 2-L20, 2-L8, 2-L16, 2-L32, 2-L5, 4-L7, 2-L25, 2-L26, 2-L10, 2-L29, 4-L5, 4-L30, 4-L31, 4-L26, 4-L2, 3-L16, 1-L3\n",
      "74 ligands remaining.\n",
      "auto-sklearn results:\n",
      "  Dataset name: phosligs\n",
      "  Metric: r2\n",
      "  Best validation score: 0.336972\n",
      "  Number of target algorithm runs: 703\n",
      "  Number of successful target algorithm runs: 579\n",
      "  Number of crashed target algorithm runs: 108\n",
      "  Number of target algorithms that exceeded the time limit: 14\n",
      "  Number of target algorithms that exceeded the memory limit: 2\n",
      "\n",
      "[(0.360000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer', 'feature_preprocessor:__choice__': 'pca', 'regressor:__choice__': 'decision_tree', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00018895134611293535, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 567, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform', 'feature_preprocessor:pca:keep_variance': 0.5830797364441707, 'feature_preprocessor:pca:whiten': 'True', 'regressor:decision_tree:criterion': 'mae', 'regressor:decision_tree:max_depth_factor': 0.4226488652822822, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 12, 'regressor:decision_tree:min_samples_split': 9, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
      "dataset_properties={\n",
      "  'task': 4,\n",
      "  'sparse': False,\n",
      "  'multioutput': False,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})),\n",
      "(0.260000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:__choice__': 'random_trees_embedding', 'regressor:__choice__': 'adaboost', 'feature_preprocessor:random_trees_embedding:bootstrap': 'False', 'feature_preprocessor:random_trees_embedding:max_depth': 5, 'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None', 'feature_preprocessor:random_trees_embedding:min_samples_leaf': 10, 'feature_preprocessor:random_trees_embedding:min_samples_split': 14, 'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0, 'feature_preprocessor:random_trees_embedding:n_estimators': 20, 'regressor:adaboost:learning_rate': 1.4412978188459482, 'regressor:adaboost:loss': 'exponential', 'regressor:adaboost:max_depth': 9, 'regressor:adaboost:n_estimators': 100},\n",
      "dataset_properties={\n",
      "  'task': 4,\n",
      "  'sparse': False,\n",
      "  'multioutput': False,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})),\n",
      "(0.200000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:__choice__': 'random_trees_embedding', 'regressor:__choice__': 'k_nearest_neighbors', 'feature_preprocessor:random_trees_embedding:bootstrap': 'False', 'feature_preprocessor:random_trees_embedding:max_depth': 5, 'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None', 'feature_preprocessor:random_trees_embedding:min_samples_leaf': 9, 'feature_preprocessor:random_trees_embedding:min_samples_split': 11, 'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0, 'feature_preprocessor:random_trees_embedding:n_estimators': 54, 'regressor:k_nearest_neighbors:n_neighbors': 2, 'regressor:k_nearest_neighbors:p': 2, 'regressor:k_nearest_neighbors:weights': 'distance'},\n",
      "dataset_properties={\n",
      "  'task': 4,\n",
      "  'sparse': False,\n",
      "  'multioutput': False,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})),\n",
      "(0.180000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none', 'feature_preprocessor:__choice__': 'random_trees_embedding', 'regressor:__choice__': 'sgd', 'feature_preprocessor:random_trees_embedding:bootstrap': 'True', 'feature_preprocessor:random_trees_embedding:max_depth': 8, 'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None', 'feature_preprocessor:random_trees_embedding:min_samples_leaf': 11, 'feature_preprocessor:random_trees_embedding:min_samples_split': 16, 'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0, 'feature_preprocessor:random_trees_embedding:n_estimators': 10, 'regressor:sgd:alpha': 0.00020501474445551446, 'regressor:sgd:average': 'True', 'regressor:sgd:fit_intercept': 'True', 'regressor:sgd:learning_rate': 'constant', 'regressor:sgd:loss': 'epsilon_insensitive', 'regressor:sgd:penalty': 'l2', 'regressor:sgd:tol': 0.00039152734529917626, 'regressor:sgd:epsilon': 0.042418060658127914, 'regressor:sgd:eta0': 0.005901423946669153},\n",
      "dataset_properties={\n",
      "  'task': 4,\n",
      "  'sparse': False,\n",
      "  'multioutput': False,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})),\n",
      "]\n",
      "R2 score: -1.2601204728330901\n"
     ]
    }
   ],
   "source": [
    "# needed for automl regression\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import autosklearn.regression\n",
    "\n",
    "# my imports\n",
    "from dcekit.sampling import kennard_stone\n",
    "\n",
    "X, y, feature_weights, sample_weights, ligNames =  loadData(r'data_config.json',zeroReplace=0.01,removeLessThan=2,removeGreaterThan=None)\n",
    "ttd = types.SimpleNamespace(X=X, y=y, f_weights=feature_weights, s_weights=sample_weights, ln=ligNames)\n",
    "# print(\"this is ttd.y \",ttd.y)\n",
    "X_train, X_test, y_train, y_test, f_weights_train, f_weights_test, s_weights_train, s_weights_test, ln_train, ln = splitData(ttd, randState=1, splitter='kennard_stone', trainSize=0.8)\n",
    "\n",
    "# do regression\n",
    "\n",
    "automl = autosklearn.regression.AutoSklearnRegressor(\n",
    "    time_left_for_this_task=2400,\n",
    "    per_run_time_limit=60,\n",
    "    tmp_folder='/home/jackson/Desktop/git-repos/phosphine-ligands/auto-ml/auto-regression-tmp',\n",
    "    output_folder='/home/jackson/Desktop/git-repos/phosphine-ligands/auto-ml/auto-regression-out',\n",
    "    n_jobs=10,\n",
    "    memory_limit=4000\n",
    ")\n",
    "automl.fit(X_train, y_train, X_test=X_test, y_test=y_test, dataset_name='phosligs')\n",
    "print(automl.sprint_statistics())\n",
    "print(automl.show_models())\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "print(\"R2 score:\", sklearn.metrics.r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
